{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:23<00:00, 11.61s/it]\n",
      "Starting from v4.46, the `logits` model output will have the same type as the model (except at train time, where it will always be FP32)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'CausalLMOutputWithPast' object has no attribute 'last_hidden_state'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 47\u001b[0m\n\u001b[0;32m     44\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m embeddings\n\u001b[0;32m     46\u001b[0m \u001b[38;5;66;03m# Generate embeddings for categories\u001b[39;00m\n\u001b[1;32m---> 47\u001b[0m category_embeddings \u001b[38;5;241m=\u001b[39m [\u001b[43mget_embeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcategory\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m category \u001b[38;5;129;01min\u001b[39;00m categories]\n\u001b[0;32m     49\u001b[0m \u001b[38;5;66;03m# Function to classify articles\u001b[39;00m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mclassify_article\u001b[39m(article):\n",
      "Cell \u001b[1;32mIn[6], line 43\u001b[0m, in \u001b[0;36mget_embeddings\u001b[1;34m(text)\u001b[0m\n\u001b[0;32m     41\u001b[0m inputs \u001b[38;5;241m=\u001b[39m tokenizer(text, return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m, padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, truncation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m---> 43\u001b[0m     embeddings \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlast_hidden_state\u001b[49m\u001b[38;5;241m.\u001b[39mmean(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# Average pooling\u001b[39;00m\n\u001b[0;32m     44\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m embeddings\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'CausalLMOutputWithPast' object has no attribute 'last_hidden_state'"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModel, AutoModelForCausalLM\n",
    "import torch\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/phi-2\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"microsoft/phi-2\")\n",
    "\n",
    "# Define a padding token if it doesn't exist\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token  # Set the padding token to the end-of-sequence token\n",
    "\n",
    "# Example articles\n",
    "articles = [\n",
    "    {\n",
    "        \"title\": \"Protests Erupt in the Capital\",\n",
    "        \"description\": \"Citizens are rallying against new legislation.\"\n",
    "    },\n",
    "    {\n",
    "        \"title\": \"Hurricane Causes Widespread Damage\",\n",
    "        \"description\": \"The hurricane has left thousands homeless.\"\n",
    "    },\n",
    "    {\n",
    "        \"title\": \"A New Vaccine Offers Hope\",\n",
    "        \"description\": \"Scientists have developed a vaccine that is 90% effective.\"\n",
    "    },\n",
    "    {\n",
    "        \"title\": \"Earthquake Rocks the City\",\n",
    "        \"description\": \"A major earthquake has struck, causing extensive damage.\"\n",
    "    }\n",
    "]\n",
    "\n",
    "# Define categories\n",
    "categories = [\n",
    "    \"Terrorism / protest / political unrest / riot\",\n",
    "    \"Positive / Uplifting\",\n",
    "    \"Natural Disasters\",\n",
    "    \"Others\"\n",
    "]\n",
    "\n",
    "# Function to generate embeddings\n",
    "def get_embeddings(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "    with torch.no_grad():\n",
    "        embeddings = model(**inputs).last_hidden_state.mean(dim=1)  # Average pooling\n",
    "    return embeddings\n",
    "\n",
    "# Generate embeddings for categories\n",
    "category_embeddings = [get_embeddings(category) for category in categories]\n",
    "\n",
    "# Function to classify articles\n",
    "def classify_article(article):\n",
    "    full_text = f\"{article['title']}: {article['description']}\"\n",
    "    article_embedding = get_embeddings(full_text)\n",
    "\n",
    "    # Calculate cosine similarity\n",
    "    similarities = []\n",
    "    for category_embedding in category_embeddings:\n",
    "        sim = torch.nn.functional.cosine_similarity(article_embedding, category_embedding)\n",
    "        similarities.append(sim.item())\n",
    "    \n",
    "    # Get the category with the highest similarity\n",
    "    max_index = similarities.index(max(similarities))\n",
    "    return categories[max_index]\n",
    "\n",
    "# Classify each article\n",
    "for article in articles:\n",
    "    category = classify_article(article)\n",
    "    print(f\"Title: {article['title']}\\nCategory: {category}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Protests Erupt in the Capital\n",
      "Category: Terrorism / protest / political unrest / riot\n",
      " Similarity: 0.657482385635376\n",
      "Title: Hurricane Causes Widespread Damage\n",
      "Category: Natural Disasters\n",
      " Similarity: 0.658108115196228\n",
      "Title: A New Vaccine Offers Hope\n",
      "Category: Others\n",
      " Similarity: 0.5682249665260315\n",
      "Title: Earthquake Rocks the City\n",
      "Category: Natural Disasters\n",
      " Similarity: 0.6053272485733032\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import DistilBertTokenizer, DistilBertModel\n",
    "\n",
    "# Check for GPU availability and set the device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load the DistilBERT model and tokenizer\n",
    "tokenizer = DistilBertTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "model = DistilBertModel.from_pretrained(\"distilbert-base-uncased\").to(device)\n",
    "\n",
    "# Define a padding token if it doesn't exist\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token  # Set the padding token to the end-of-sequence token\n",
    "\n",
    "# Example articles\n",
    "articles = [\n",
    "    {\n",
    "        \"title\": \"Protests Erupt in the Capital\",\n",
    "        \"description\": \"Citizens are rallying against new legislation.\"\n",
    "    },\n",
    "    {\n",
    "        \"title\": \"Hurricane Causes Widespread Damage\",\n",
    "        \"description\": \"The hurricane has left thousands homeless.\"\n",
    "    },\n",
    "    {\n",
    "        \"title\": \"A New Vaccine Offers Hope\",\n",
    "        \"description\": \"Scientists have developed a vaccine that is 90% effective.\"\n",
    "    },\n",
    "    {\n",
    "        \"title\": \"Earthquake Rocks the City\",\n",
    "        \"description\": \"A major earthquake has struck, causing extensive damage.\"\n",
    "    }\n",
    "]\n",
    "\n",
    "# Define categories\n",
    "categories = [\n",
    "    \"Terrorism / protest / political unrest / riot\",\n",
    "    \"Positive / Uplifting\",\n",
    "    \"Natural Disasters\"\n",
    "]\n",
    "\n",
    "# Function to generate embeddings\n",
    "def get_embeddings(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True).to(device)  # Move inputs to GPU\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        embeddings = outputs.last_hidden_state.mean(dim=1)  # Average pooling over the last hidden state\n",
    "    return embeddings\n",
    "\n",
    "# Generate embeddings for categories\n",
    "category_embeddings = [get_embeddings(category) for category in categories]\n",
    "\n",
    "# Function to classify articles\n",
    "def classify_article(article):\n",
    "    full_text = f\"{article['title']}: {article['description']}\"\n",
    "    article_embedding = get_embeddings(full_text)\n",
    "\n",
    "    # Calculate cosine similarity\n",
    "    similarities = []\n",
    "    for category_embedding in category_embeddings:\n",
    "        sim = torch.nn.functional.cosine_similarity(article_embedding, category_embedding)\n",
    "        similarities.append(sim.item())\n",
    "    \n",
    "    # Get the category with the highest similarity\n",
    "    max_index = similarities.index(max(similarities))\n",
    "    max_sim = max(similarities)\n",
    "    if max_sim>0.6:\n",
    "        return categories[max_index],max_sim\n",
    "    else :\n",
    "        return \"Others\",max_sim\n",
    "\n",
    "# Classify each article\n",
    "for article in articles:\n",
    "    category,max_sim = classify_article(article)\n",
    "    print(f\"Title: {article['title']}\\nCategory: {category}\\n Similarity: {max_sim}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
